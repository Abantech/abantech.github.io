

_Revolutionizing the way we shape our world_

[About Us]( #about) ~ [Our Team](#team) ~ [Efficio Middleware]( #middleware ) ~ [Demos and Videos]( #demo )

<span style=display:none; >[View as web page]( http://abantech.github.io/libs "View file as a web page." ) </span>
<input type=button value='View file as source code on GitHub' onclick=window.location.href='https://github.com/abantach/libs/tree/gh-pages'; />


<a name=about class=abou >About Us</a>
===

Abantech's mission is to break down the barriers that have prevented people from working efficiently with software systems. We wish to allow people to break free of the artificial restrictions imposed by working with primitive devices (like the mouse, keyboard, etc) and to be unencumbered by the specialization required to work with 3D applications.

We want to allow people to do things in ways that have been traditionally difficult or impossible. We want to allow people to better be able to express their creativity, to collaborate, to invent and innovate. To boldly do what they couldn't (easily) do before.

We want empower peopls ideas and action' to be able to better work in 3D. We seek to tear down the "barriers-to-entry" so as to overcome the obstacles to their productivity.


<a name=team >Our Team</a>
===

The team's skills allows for complete coverage of all technical subject matters through deep technical expertise. Our team is comprised of subject matter experts in all relevant areas in Software architecture and development, 3D technology, Human Computer Interaction (human factors and applied cognition), Physics and scientific algorithms.

But most importantly, we are all passionate about bringing the ability to create help others achieve whatever they would be willing to set their minds and hearts to do.

Gregory Melencio: CEO, President, and Chairman

* Currently Software Architect and Development Manager with Accenture. 
* Over 15 years software development and architecture experience.
* Previously worked for National Science Foundation.
* Architected several solutions for the Federal Government with an unbroken track-record of successful implementation of high-availability, mission-critical systems. 
* Always been an inventor and innovator.

Theo Armour: Chief Technology Officer

* Well-respected technologist who started 3D at Autodesk, program manager for 3 releases of AutoCAD. 
* Tech founder and angel investor.
* Hack client-side realtime 3D JavaScript Three.js/Leap - all FOSS on GitHub.

James Stephens: Vice President of Development

* Senior Software Developer at Accenture. Professional background in Federal Technology Consulting and System Integration
* Extensive experience in web, software development, and 3D development. _Magna Cum Laude_ BS Applied Mathematics

John Bledsoe: Physicist and Scientific Algorithms Expert

* 30+ years of scientific programming and expert at creating scientific algorithms. 
* Experience with a wide array of software systems, programming languanges, and platforms.

Ryan McGarry: Human Factors/HCI (Human-Computer Interaction) Expert

* PhD Candidate in Human Factors and Applied Cognition. 
* Extensive UI research experience and design for improving interactions with computer interfaces/machines.
* Published studies for top research journals. Education at the doctoral level from GMU in human-computer interaction (HCI). 
* Academic background in Computer Science.

<a name=middleware >Efficio Middleware</a>
===

At a high-level, Efficio Middleware is a set of components intended to manage the control and interaction between the enduser input (as provided by the Hardware APIs) and the consuming the 3D modeling software. Within the 3D consuming 3D software, it defining the interaction between the Assets within the system, marshalling of context-aware instructions.

Among Efficio's Goals are: To enable hand-motion-sensing devices - such as Leap, RealSense, Kinect, etc - to communicate effectively with 3D design systems such as CAD/CAM programs and game engines (consuming system). We extend beyond the abstracting human input from NI devices (as with OpenNI) to translate this into actions. That is, we attempt to recognize/perceive user intent and effect this through the execution of functions (or a series of functions) in the consuming system. This is most closely resembles Motion Planning, but applied to functions executed in the consuming system. To capture the huge subtlety and sensitivity of finger/skeletal movements - along with the extremely high bandwidth incurred - and channel this information as exquisitely useful instructions for creating objects of immense detail, craftsmanship and sophistication.

Visit Demo Page for a live demo or videos

<a name=demo>Live Demo and Videos</a>
===

If you have a LEAP device installed with the latest SDK: View a Live Demo HERE

Otherwise, below are videos of some the features currently implemented into the early prototype

Note: We're still coming up with our MVP so stay tuned for updates!

Copyright &copy; 2015 Abantech
